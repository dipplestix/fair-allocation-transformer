{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c54c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_components import GLU, MHA\n",
    "from fatransformer import FATransformer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from helpers import get_nash_welfare\n",
    "from typing import Optional\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79803429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: obmpqm8u\n",
      "Sweep URL: https://wandb.ai/dieplstks/fa-transformer-sweep/sweeps/obmpqm8u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fexst8pn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 1536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 3.429339118090045e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tm: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_output_layers: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsteps: 20000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.014630721343048138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdieplstks\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dipplestix/Projects/fair-allocation-transformer/fatransformer/wandb/run-20250925_142833-fexst8pn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dieplstks/fa-transformer-sweep/runs/fexst8pn' target=\"_blank\">vague-sweep-1</a></strong> to <a href='https://wandb.ai/dieplstks/fa-transformer-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dieplstks/fa-transformer-sweep/sweeps/obmpqm8u' target=\"_blank\">https://wandb.ai/dieplstks/fa-transformer-sweep/sweeps/obmpqm8u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dieplstks/fa-transformer-sweep' target=\"_blank\">https://wandb.ai/dieplstks/fa-transformer-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dieplstks/fa-transformer-sweep/sweeps/obmpqm8u' target=\"_blank\">https://wandb.ai/dieplstks/fa-transformer-sweep/sweeps/obmpqm8u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dieplstks/fa-transformer-sweep/runs/fexst8pn' target=\"_blank\">https://wandb.ai/dieplstks/fa-transformer-sweep/runs/fexst8pn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb8fc5f0710>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb90af354c0, execution_count=2 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb90b256780, raw_cell=\"import wandb\n",
      "import torch.optim as optim\n",
      "\n",
      "# Define..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://wsl%2Bubuntu/home/dipplestix/Projects/fair-allocation-transformer/fatransformer/faformer_sweep.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/paper_reimps/.conda/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:446\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/paper_reimps/.conda/lib/python3.12/site-packages/wandb/sdk/interface/interface.py:729\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    728\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 729\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/paper_reimps/.conda/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py:359\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/paper_reimps/.conda/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/paper_reimps/.conda/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:225\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    223\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    224\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/paper_reimps/.conda/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:157\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/paper_reimps/.conda/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    152\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/paper_reimps/.conda/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:132\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    130\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in threading.excepthook:\n",
      "Exception ignored in thread started by: <bound method Thread._bootstrap of <Thread(Thread-5 (_run_job), stopped 140432411457088)>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipplestix/Projects/paper_reimps/.conda/lib/python3.12/threading.py\", line 1030, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/dipplestix/Projects/paper_reimps/.conda/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self._invoke_excepthook(self)\n",
      "  File \"/home/dipplestix/Projects/paper_reimps/.conda/lib/python3.12/threading.py\", line 1389, in invoke_excepthook\n",
      "    local_print(\"Exception in threading.excepthook:\",\n",
      "  File \"/home/dipplestix/Projects/paper_reimps/.conda/lib/python3.12/site-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/home/dipplestix/Projects/paper_reimps/.conda/lib/python3.12/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/home/dipplestix/Projects/paper_reimps/.conda/lib/python3.12/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipplestix/Projects/paper_reimps/.conda/lib/python3.12/site-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/home/dipplestix/Projects/paper_reimps/.conda/lib/python3.12/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/home/dipplestix/Projects/paper_reimps/.conda/lib/python3.12/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the sweep configuration for Bayesian optimization\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"goal\": \"maximize\", \"name\": \"nash_welfare\"},\n",
    "    \"parameters\": {\n",
    "        \"d_model\": {\n",
    "            \"values\": [768, 1536]\n",
    "        },\n",
    "        \"num_heads\": {\n",
    "            \"values\": [4, 8, 12, 16]\n",
    "        },\n",
    "        \"lr\": {\n",
    "            \"min\": 1e-5,\n",
    "            \"max\": 1e-4,\n",
    "            \"distribution\": \"log_uniform_values\"\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [512, 1024, 2048, 4096]\n",
    "        },\n",
    "        \"num_output_layers\": {\n",
    "            \"values\": [1, 2, 3, 4, 5]\n",
    "        },\n",
    "        \"weight_decay\": {\n",
    "            \"min\": 1e-4,\n",
    "            \"max\": 1e-1,\n",
    "            \"distribution\": \"log_uniform_values\"\n",
    "        },\n",
    "        \"n\": {\n",
    "            \"value\": 10\n",
    "        },\n",
    "        \"m\": {\n",
    "            \"value\": 14\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"value\": 0.0\n",
    "        },\n",
    "        \"steps\": {\n",
    "            \"value\": 20000\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"fa-transformer-sweep\")\n",
    "\n",
    "def train():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    n = config.n\n",
    "    m = config.m\n",
    "\n",
    "    model = FATransformer(\n",
    "        n, m, config.d_model, config.num_heads, config.num_output_layers, config.dropout\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), lr=config.lr, weight_decay=config.weight_decay\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.steps)\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 20  # Number of steps to wait for improvement\n",
    "    min_delta = 1e-5  # Minimum change to qualify as improvement\n",
    "    best_nash_welfare = float('-inf')\n",
    "    steps_without_improvement = 0\n",
    "\n",
    "    for step in range(config.steps):\n",
    "        u = torch.rand(config.batch_size, n, m, device=device)\n",
    "\n",
    "        allocation = model(u)\n",
    "        nash_welfare = get_nash_welfare(u, allocation, reduction=\"mean\")\n",
    "\n",
    "        loss = -nash_welfare\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        wandb.log({\n",
    "            \"step\": step,\n",
    "            \"loss\": loss.item(),\n",
    "            \"nash_welfare\": nash_welfare.item(),\n",
    "            \"lr\": scheduler.get_last_lr()[0]\n",
    "        })\n",
    "\n",
    "        # Early stopping logic\n",
    "        if nash_welfare.item() > best_nash_welfare + min_delta:\n",
    "            best_nash_welfare = nash_welfare.item()\n",
    "            steps_without_improvement = 0\n",
    "        else:\n",
    "            steps_without_improvement += 1\n",
    "\n",
    "        if steps_without_improvement >= patience:\n",
    "            print(f\"Early stopping at step {step} with best nash_welfare {best_nash_welfare:.6f}\")\n",
    "            break\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "# To launch the sweep agent, run this cell or in a script:\n",
    "wandb.agent(sweep_id, function=train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588e54b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
